{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANLY 590 Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Team\n",
    "Team Member: Mengci Duan, Wupeng Han and Yipin Lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Project’s Goal and Objectives\n",
    "    \"Quick, Draw!\" was released as an experimental game to educate the public in a playful way about how AI works. The game prompts users to draw an image depicting a certain category, such as ”banana,” “table,” etc. The game generated more than 1B drawings, of which a subset was publicly released as the basis for this competition’s training set. That subset contains 50M drawings encompassing 340 label categories.\n",
    "\n",
    "\tThe problem here is that since the training data comes from the game itself, drawings can be incomplete or may not match the label. So we want to use convolutional neural networks to build a classifier that can effectively learn from this noisy data and perform well on a manually-labeled test set from a different distribution.\n",
    "    \n",
    "    CNN is our first choice to build the image classifier, since the data will be classified are images which have a natural structure such as nearby entries are correlated. As we know, CNN can take advantage of local spatial coherence in the input, which allows them to have fewer weights as some parameters are shared. This quality makes CNN especially well suited to extract relevant information at a low computational cost. So CNN is unique compared to other methods.\n",
    "    \n",
    "    As mentioned before, we will use the subset of the game data which contains 50M drawings encompassing 340 label categories as our training set and the complementary set of the data as our test set. The data can be found on Kaggle \n",
    "(https://www.kaggle.com/c/quickdraw-doodle-recognition/data).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data\n",
    "    The training dataset has six features “countrycode” “drawing” “key_id” “recognized” “timestamp” “word” with an appropriate schema. The limitation of this data is that no feature shows if the drawing was finished, so we have many incomplete noise data when we do the classification. If the game can add a question such as “Did you finish your drawing?” after it recognized a drawing and make it an additional boolean value feature in the dataset, it would be easier for the machine to learn the pattern of each classification. The current data source is appropriate since it is officially released by Google and generated by the \"Quick, Draw!” game directly which is clean and formatted. This is a supervised problem, our input feature vector would be <“countrycode” “drawing” “recognized” “timestamp”> and our output feature would be “word”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assessment Metrics  \n",
    "    Since the problem is a supervised multi-class classification problem, cross entropy will be used in the project as the loss metrics. The dataset is too large for our computer to process. Thus about 50000 doodles for each word will be used as the training dataset by random selection, and 50000 doodles in the datasets will be used as the test dataset by random selection. \n",
    "    In the project, KNN, Random Forest, SVM will be used as baseline models to compare with the CNN model. We expect that the CNN model will have the best prediction accuracy, KNN, RF, and  SVM may have similar prediction performance. There is a lot of attention on deep learning for content-based image classification at the moment: RNN, CNN, LTSM.  Employing CNN in image classification problem is popular. As CNN extracts spatial features and RNN extracts temporal features, for image recognition, the project chooses CNN over RNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Approach \n",
    "    The expected outcomes will be the categories of each graph. As part (4) mentioned, we will first select some traditional machine learning algorithms to be our baseline models. Then, we conduct classification using different CNN frameworks, such as VGG, and explore how to tune a deep learning model. The possible limitation of our approach is that we can merely select a small part of the dataset for our project because the size of the full dataset is huge.\n",
    "    We will try to use local machine first. If we cannot run our program smoothly, then we will run it on AWS. However, the main limitation is cost. Running a project on AWS is very expensive.\n",
    "    In this project, we will mainly use Tensorflow or Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
